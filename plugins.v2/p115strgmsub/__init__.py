"""
115ç½‘ç›˜è®¢é˜…è¿½æ›´æ’ä»¶
ç»“åˆMoviePilotè®¢é˜…åŠŸèƒ½ï¼Œè‡ªåŠ¨æœç´¢115ç½‘ç›˜èµ„æºå¹¶è½¬å­˜ç¼ºå¤±å‰§é›†
"""
import re
import datetime
from pathlib import Path
from threading import Lock
from typing import Optional, Any, List, Dict, Tuple
from pydantic import BaseModel

import pytz
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger

from app.core.config import settings, global_vars
from app.core.event import Event, eventmanager
from app.core.metainfo import MetaInfo
from app.chain.download import DownloadChain
from app.chain.subscribe import SubscribeChain
from app.db import SessionFactory
from app.db.subscribe_oper import SubscribeOper
from app.db.downloadhistory_oper import DownloadHistoryOper
from app.db.models.site import Site
from app.log import logger
from app.plugins import _PluginBase
from app.schemas import MediaInfo
from app.schemas.types import EventType, MediaType, NotificationType
from app.utils.string import StringUtils

from .pansou import PanSouClient
from .p115client import P115ClientManager
from .nullbr import NullbrClient
from .ui_config import UIConfig
from .file_matcher import FileMatcher, SubscribeFilter

lock = Lock()


class P115StrgmSub(_PluginBase):
    """115ç½‘ç›˜è®¢é˜…è¿½æ›´æ’ä»¶"""

    # æ’ä»¶åç§°
    plugin_name = "115ç½‘ç›˜è®¢é˜…è¿½æ›´"
    # æ’ä»¶æè¿°
    plugin_desc = "ç»“åˆMoviePilotè®¢é˜…åŠŸèƒ½ï¼Œè‡ªåŠ¨æœç´¢115ç½‘ç›˜èµ„æºå¹¶è½¬å­˜ç¼ºå¤±çš„ç”µå½±å’Œå‰§é›†ã€‚"
    # æ’ä»¶å›¾æ ‡
    plugin_icon = "https://raw.githubusercontent.com/jxxghp/MoviePilot-Plugins/main/icons/cloud.png"
    # æ’ä»¶ç‰ˆæœ¬
    plugin_version = "1.0.9"
    # æ’ä»¶ä½œè€…
    plugin_author = "mrtian2016"
    # ä½œè€…ä¸»é¡µ
    author_url = "https://github.com/mrtian2016"
    # æ’ä»¶é…ç½®é¡¹IDå‰ç¼€
    plugin_config_prefix = "p115strgmsub_"
    # åŠ è½½é¡ºåº
    plugin_order = 20
    # å¯ä½¿ç”¨çš„ç”¨æˆ·çº§åˆ«
    auth_level = 1

    # ç§æœ‰å˜é‡
    _scheduler: Optional[BackgroundScheduler] = None

    # é…ç½®å±æ€§
    _enabled: bool = False
    _onlyonce: bool = False
    _cron: str = "30 */8 * * *"
    _notify: bool = False
    _cookies: str = ""
    _pansou_enabled: bool = True  # æ˜¯å¦å¯ç”¨ PanSou æœç´¢
    _pansou_url: str = "https://so.252035.xyz"
    _pansou_username: str = ""
    _pansou_password: str = ""
    _pansou_auth_enabled: bool = False
    _pansou_channels: str = "QukanMovie"  # TGæœç´¢é¢‘é“åˆ—è¡¨,ç”¨é€—å·åˆ†éš”
    _save_path: str = "/æˆ‘çš„æ¥æ”¶/MoviePilot/TV"  # ç”µè§†å‰§è½¬å­˜ç›®å½•
    _movie_save_path: str = "/æˆ‘çš„æ¥æ”¶/MoviePilot/Movie"  # ç”µå½±è½¬å­˜ç›®å½•
    _only_115: bool = True  # åªæœç´¢115ç½‘ç›˜èµ„æº
    _exclude_subscribes: List[int] = []  # æ’é™¤çš„è®¢é˜…IDåˆ—è¡¨
    _nullbr_enabled: bool = False  # æ˜¯å¦å¯ç”¨ Nullbr æŸ¥è¯¢
    _nullbr_appid: str = ""  # Nullbr APP IDï¼ˆæ–°å­—æ®µåï¼Œé¿å…åŠ è½½æ—§é…ç½®ï¼‰
    _nullbr_api_key: str = ""  # Nullbr API Key
    _nullbr_priority: bool = True  # Nullbr ä¼˜å…ˆï¼ˆTrue: ä¼˜å…ˆä½¿ç”¨ Nullbrï¼ŒFalse: ä¼˜å…ˆä½¿ç”¨ PanSouï¼‰
    _hdhive_enabled: bool = False  # æ˜¯å¦å¯ç”¨ HDHive æŸ¥è¯¢
    _hdhive_username: str = ""  # HDHive ç”¨æˆ·å
    _hdhive_password: str = ""  # HDHive å¯†ç 
    _hdhive_cookie: str = ""  # HDHive Cookie
    _block_system_subscribe: bool = False  # æ˜¯å¦å±è”½ç³»ç»Ÿè®¢é˜…
    _max_transfer_per_sync: int = 50  # å•æ¬¡åŒæ­¥æœ€å¤§è½¬å­˜æ•°é‡ï¼Œé˜²æ­¢é£æ§
    _batch_size: int = 20  # æ‰¹é‡è½¬å­˜æ¯æ‰¹æ–‡ä»¶æ•°
    _skip_other_season_dirs: bool = True  # è·³è¿‡å…¶ä»–å­£ç›®å½•ä»¥å‡å°‘APIè°ƒç”¨
    # è¿è¡Œæ—¶å¯¹è±¡
    _pansou_client: Optional[PanSouClient] = None
    _p115_manager: Optional[P115ClientManager] = None
    _nullbr_client: Optional[NullbrClient] = None
    _hdhive_client: Optional[Any] = None  # HDHive å®¢æˆ·ç«¯

    def _download_so_file(self):
        """
        ä¸‹è½½ hdhive .so æ–‡ä»¶åˆ° lib ç›®å½•
        
        ä» GitHub ä¸‹è½½ç¼–è¯‘å¥½çš„ .so æ–‡ä»¶ï¼Œç”¨äº HDHive åŠŸèƒ½
        """
        import platform
        import urllib.request
        import urllib.error
        
        # ç¡®å®šç›®æ ‡ç›®å½•
        lib_dir = Path(__file__).parent / "lib"
        lib_dir.mkdir(parents=True, exist_ok=True)
        
        # ç¡®å®šç³»ç»Ÿæ¶æ„å’Œå¹³å°
        machine = platform.machine().lower()
        system = platform.system().lower()
        
        # æ˜ å°„å¸¸è§çš„æ¶æ„åç§°
        arch_map = {
            "x86_64": "x86_64",
            "amd64": "x86_64",
            "aarch64": "aarch64",
            "arm64": "aarch64",
        }
        arch = arch_map.get(machine, machine)
        
        # æ˜ å°„å¹³å°åç§°
        platform_map = {
            "linux": "linux-gnu",
            "darwin": "darwin",
        }
        plat = platform_map.get(system, system)
        
        # æ„å»ºæ–‡ä»¶åï¼ˆLinux: hdhive.cpython-312-x86_64-linux-gnu.soï¼‰
        # ç›®å‰åªæ”¯æŒ Linux x86_64
        so_filename = f"hdhive.cpython-312-{arch}-{plat}.so"
        target_path = lib_dir / so_filename
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½
        if target_path.exists():
            logger.debug(f"hdhive .so æ–‡ä»¶å·²å­˜åœ¨: {target_path}")
            return
        
        # GitHub åŸå§‹æ–‡ä»¶ URL
        
        base_url = "https://ghfast.top/https://raw.githubusercontent.com/mrtian2016/hdhive_resource/main/"
        download_url = f"{base_url}/{so_filename}"
        
        logger.info(f"å¼€å§‹ä¸‹è½½ hdhive .so æ–‡ä»¶: {download_url}")
        
        try:
            # ä¸‹è½½æ–‡ä»¶
            with urllib.request.urlopen(download_url, timeout=120) as response:
                content = response.read()
            
            # ä¿å­˜åˆ°æœ¬åœ°
            with open(target_path, "wb") as f:
                f.write(content)
            
            # è®¾ç½®å¯æ‰§è¡Œæƒé™
            import os
            os.chmod(target_path, 0o755)
            
            logger.info(f"âœ“ hdhive .so æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {target_path}")
            
        except urllib.error.HTTPError as e:
            if e.code == 404:
                logger.warning(f"âš ï¸ hdhive .so æ–‡ä»¶ä¸å­˜åœ¨ï¼ˆå½“å‰å¹³å°: {system}/{arch}ï¼‰ï¼ŒHDHive åŠŸèƒ½å¯èƒ½æ— æ³•ä½¿ç”¨")
            else:
                logger.error(f"ä¸‹è½½ hdhive .so æ–‡ä»¶å¤±è´¥ (HTTP {e.code}): {e}")
        except urllib.error.URLError as e:
            logger.error(f"ä¸‹è½½ hdhive .so æ–‡ä»¶å¤±è´¥ï¼ˆç½‘ç»œé”™è¯¯ï¼‰: {e}")
        except Exception as e:
            logger.error(f"ä¸‹è½½ hdhive .so æ–‡ä»¶å¤±è´¥: {e}")

    def init_plugin(self, config: dict = None):
        """åˆå§‹åŒ–æ’ä»¶"""
        # åœæ­¢ç°æœ‰ä»»åŠ¡
        self.stop_service()

        # ä¸‹è½½.soæ–‡ä»¶
        self._download_so_file()

        # åŠ è½½é…ç½®
        if config:
            self._enabled = config.get("enabled", False)
            self._cron = config.get("cron", "30 */8 * * *")
            self._notify = config.get("notify", False)
            self._onlyonce = config.get("onlyonce", False)
            self._cookies = config.get("cookies", "")
            self._pansou_enabled = config.get("pansou_enabled", True)
            self._pansou_url = config.get("pansou_url", "https://so.252035.xyz/")
            self._pansou_username = config.get("pansou_username", "")
            self._pansou_password = config.get("pansou_password", "")
            self._pansou_auth_enabled = config.get("pansou_auth_enabled", False)
            self._pansou_channels = config.get("pansou_channels", "QukanMovie")
            self._save_path = config.get("save_path", "/æˆ‘çš„æ¥æ”¶/MoviePilot/TV")
            self._movie_save_path = config.get("movie_save_path", "/æˆ‘çš„æ¥æ”¶/MoviePilot/Movie")
            self._only_115 = config.get("only_115", True)
            self._exclude_subscribes = config.get("exclude_subscribes", []) or []
            self._nullbr_enabled = config.get("nullbr_enabled", False)
            self._nullbr_appid = config.get("nullbr_appid", "")
            self._nullbr_api_key = config.get("nullbr_api_key", "")
            self._nullbr_priority = config.get("nullbr_priority", True)
            self._hdhive_enabled = config.get("hdhive_enabled", False)
            self._hdhive_username = config.get("hdhive_username", "")
            self._hdhive_password = config.get("hdhive_password", "")
            self._hdhive_cookie = config.get("hdhive_cookie", "")
            self._max_transfer_per_sync = int(config.get("max_transfer_per_sync", 50) or 50)
            self._batch_size = int(config.get("batch_size", 20) or 20)
            self._skip_other_season_dirs = config.get("skip_other_season_dirs", True)

            # å¤„ç†å±è”½ç³»ç»Ÿè®¢é˜…å¼€å…³
            new_block_state = config.get("block_system_subscribe", False)
            old_block_state = self._block_system_subscribe
            self._block_system_subscribe = new_block_state
            
            # å¼€å…³çŠ¶æ€å˜åŒ–æ—¶ï¼Œæ›´æ–°æ‰€æœ‰è®¢é˜…çš„siteså­—æ®µ
            if new_block_state != old_block_state:
                self._update_subscribe_sites(new_block_state)

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self._init_clients()

        if self._enabled or self._onlyonce:
            if self._onlyonce:
                self._scheduler = BackgroundScheduler(timezone=settings.TZ)
                logger.info("115ç½‘ç›˜è®¢é˜…è¿½æ›´æœåŠ¡å¯åŠ¨ï¼Œç«‹å³è¿è¡Œä¸€æ¬¡")
                self._scheduler.add_job(
                    func=self.sync_subscribes,
                    trigger='date',
                    run_date=datetime.datetime.now(tz=pytz.timezone(settings.TZ)) + datetime.timedelta(seconds=3)
                )
                if self._scheduler.get_jobs():
                    self._scheduler.print_jobs()
                    self._scheduler.start()

            if self._onlyonce:
                self._onlyonce = False
                self.__update_config()

    def _init_clients(self):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯"""
        # åˆå§‹åŒ– PanSou å®¢æˆ·ç«¯
        if self._pansou_enabled and self._pansou_url:
            self._pansou_client = PanSouClient(
                base_url=self._pansou_url,
                username=self._pansou_username,
                password=self._pansou_password,
                auth_enabled=self._pansou_auth_enabled
            )

        # åˆå§‹åŒ– Nullbr å®¢æˆ·ç«¯
        if self._nullbr_enabled:
            if not self._nullbr_appid or not self._nullbr_api_key:
                missing = []
                if not self._nullbr_appid:
                    missing.append("APP ID")
                if not self._nullbr_api_key:
                    missing.append("API Key")
                logger.warning(f"âš ï¸ Nullbr å·²å¯ç”¨ä½†ç¼ºå°‘å¿…è¦é…ç½®ï¼š{', '.join(missing)}ï¼Œå°†æ— æ³•ä½¿ç”¨ Nullbr æŸ¥è¯¢åŠŸèƒ½")
                self._nullbr_client = None
            else:
                self._nullbr_client = NullbrClient(app_id=self._nullbr_appid, api_key=self._nullbr_api_key)
                logger.info("âœ“ Nullbr å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")

        # åˆå§‹åŒ– HDHive å®¢æˆ·ç«¯
        if self._hdhive_enabled:
            if not self._hdhive_cookie and not (self._hdhive_username and self._hdhive_password):
                logger.warning("âš ï¸ HDHive å·²å¯ç”¨ä½†ç¼ºå°‘å¿…è¦é…ç½®ï¼ˆCookie æˆ– ç”¨æˆ·å/å¯†ç ï¼‰ï¼Œå°†æ— æ³•ä½¿ç”¨ HDHive æŸ¥è¯¢åŠŸèƒ½")
                self._hdhive_client = None
            elif self._hdhive_cookie:
                # ä¼˜å…ˆä½¿ç”¨ Cookie åˆå§‹åŒ–åŒæ­¥å®¢æˆ·ç«¯
                try:
                    import os
                    from .lib.hdhive import create_client as create_hdhive_client
                    proxy_host = os.environ.get("PROXY_HOST")
                    proxy = {"http": proxy_host, "https": proxy_host} if proxy_host else None
                    self._hdhive_client = create_hdhive_client(cookie=self._hdhive_cookie, proxy=proxy)
                    logger.info("âœ“ HDHive å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼ˆCookie æ¨¡å¼ï¼‰")
                except Exception as e:
                    logger.warning(f"âš ï¸ HDHive å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼š{e}")
                    self._hdhive_client = None
            else:
                # æ²¡æœ‰ Cookieï¼Œä»…è®°å½•ç”¨æˆ·åå¯†ç ï¼Œç”¨äºå¼‚æ­¥å›é€€
                logger.info("âœ“ HDHive é…ç½®å·²åŠ è½½ï¼ˆç”¨æˆ·å/å¯†ç æ¨¡å¼ï¼Œå°†ä½¿ç”¨å¼‚æ­¥å®¢æˆ·ç«¯ï¼‰")
                self._hdhive_client = None  # å¼‚æ­¥å®¢æˆ·ç«¯åœ¨æœç´¢æ—¶åŠ¨æ€åˆ›å»º

         # åˆå§‹åŒ– 115 å®¢æˆ·ç«¯
        if self._cookies:
            self._p115_manager = P115ClientManager(cookies=self._cookies)

    def get_state(self) -> bool:
        return self._enabled

    @staticmethod
    def get_command() -> List[Dict[str, Any]]:
        """å®šä¹‰è¿œç¨‹æ§åˆ¶å‘½ä»¤"""
        return [{
            "cmd": "/p115_sync",
            "event": EventType.PluginAction,
            "desc": "115ç½‘ç›˜è®¢é˜…è¿½æ›´",
            "category": "è®¢é˜…",
            "data": {
                "action": "p115_sync"
            }
        }]

    def get_api(self) -> List[Dict[str, Any]]:
        """è·å–æ’ä»¶API"""
        # return []
        return [
            {
                "path": "/search",
                "endpoint": self.api_search,
                "methods": ["GET"],
                "summary": "æœç´¢ç½‘ç›˜èµ„æº"
            },
            {
                "path": "/transfer",
                "endpoint": self.api_transfer,
                "methods": ["POST"],
                "summary": "è½¬å­˜åˆ†äº«é“¾æ¥"
            },
            {
                "path": "/clear_history",
                "endpoint": self.api_clear_history,
                "methods": ["POST"],
                "summary": "æ¸…ç©ºå†å²è®°å½•"
            },
            {
                "path": "/directories",
                "endpoint": self.api_list_directories,
                "methods": ["GET"],
                "summary": "åˆ—å‡º115ç½‘ç›˜ç›®å½•"
            }
        ]

    def get_service(self) -> List[Dict[str, Any]]:
        """æ³¨å†Œæ’ä»¶å…¬å…±æœåŠ¡"""
        if self._enabled and self._cron:
            return [{
                "id": "P115StrgmSub",
                "name": "115ç½‘ç›˜è®¢é˜…è¿½æ›´æœåŠ¡",
                "trigger": CronTrigger.from_crontab(self._cron),
                "func": self.sync_subscribes,
                "kwargs": {}
            }]
        elif self._enabled:
            return [{
                "id": "P115StrgmSub",
                "name": "115ç½‘ç›˜è®¢é˜…è¿½æ›´æœåŠ¡",
                "trigger": "interval",
                "func": self.sync_subscribes,
                "kwargs": {"hours": 6}
            }]
        return []

    def get_form(self) -> Tuple[List[dict], Dict[str, Any]]:
        """æ‹¼è£…æ’ä»¶é…ç½®é¡µé¢"""
        return UIConfig.get_form()



    def get_page(self) -> Optional[List[dict]]:
        """æ‹¼è£…æ’ä»¶è¯¦æƒ…é¡µé¢"""
        history = self.get_data('history') or []
        return UIConfig.get_page(history)


    def __update_config(self):
        """æ›´æ–°é…ç½®"""
        self.update_config({
            "enabled": self._enabled,
            "notify": self._notify,
            "onlyonce": self._onlyonce,
            "only_115": self._only_115,
            "cron": self._cron,
            "save_path": self._save_path,
            "movie_save_path": self._movie_save_path,
            "cookies": self._cookies,
            "pansou_enabled": self._pansou_enabled,
            "pansou_url": self._pansou_url,
            "pansou_username": self._pansou_username,
            "pansou_password": self._pansou_password,
            "pansou_auth_enabled": self._pansou_auth_enabled,
            "pansou_channels": self._pansou_channels,
            "nullbr_enabled": self._nullbr_enabled,
            "nullbr_appid": self._nullbr_appid,
            "nullbr_api_key": self._nullbr_api_key,
            "nullbr_priority": self._nullbr_priority,
            "hdhive_enabled": self._hdhive_enabled,
            "hdhive_username": self._hdhive_username,
            "hdhive_password": self._hdhive_password,
            "hdhive_cookie": self._hdhive_cookie,
            "exclude_subscribes": self._exclude_subscribes,
            "block_system_subscribe": self._block_system_subscribe,
            "max_transfer_per_sync": self._max_transfer_per_sync,
            "batch_size": self._batch_size,
            "skip_other_season_dirs": self._skip_other_season_dirs
        })

    def _update_subscribe_sites(self, block: bool):
        """
        å±è”½/æ¢å¤ç³»ç»Ÿè®¢é˜…
        
        :param block: True è¡¨ç¤ºå±è”½ï¼ˆæ·»åŠ id=-1çš„115ç½‘ç›˜ç«™ç‚¹ï¼Œå¹¶æ›´æ–°è®¢é˜…sitesä¸º[-1]ï¼‰ï¼Œ
                      False è¡¨ç¤ºæ¢å¤ï¼ˆåˆ é™¤è¯¥è®°å½•ï¼Œå¹¶æ¢å¤è®¢é˜…sitesä¸º[]ï¼‰
        """
        try:
            from sqlalchemy import text
            
            sites_value = [-1] if block else []
            action = "å±è”½" if block else "æ¢å¤"
            
            with SessionFactory() as db:
                # 1. æ›´æ–°æ‰€æœ‰è®¢é˜…çš„siteså­—æ®µ
                subscribes = SubscribeOper(db=db).list()
                updated_count = 0
                excluded_count = 0
                if subscribes:
                    for subscribe in subscribes:
                        if subscribe.id in self._exclude_subscribes:
                            excluded_count += 1
                            continue
                        SubscribeOper(db=db).update(subscribe.id, {"sites": sites_value})
                        updated_count += 1
                    if excluded_count:
                        logger.info(f"è·³è¿‡ {excluded_count} ä¸ªæ’é™¤è®¢é˜…")
                    logger.info(f"ç³»ç»Ÿè®¢é˜…{action}å®Œæˆï¼Œå·²æ›´æ–° {updated_count} ä¸ªè®¢é˜…çš„siteså­—æ®µä¸º {sites_value}")
                
                # 2. æ·»åŠ æˆ–åˆ é™¤id=-1çš„ç«™ç‚¹è®°å½•
                if block:
                    # å¼€å¯å±è”½ï¼šæ·»åŠ id=-1çš„ç«™ç‚¹è®°å½•
                    existing = Site.get(db, -1)
                    if not existing:
                        # ä½¿ç”¨åŸç”ŸSQLæ’å…¥ï¼Œå› ä¸ºéœ€è¦æŒ‡å®šidä¸º-1
                        db.execute(
                            text(
                                "INSERT INTO site (id, name, url, is_active, limit_interval, limit_count, limit_seconds, timeout) VALUES (:id, :name, :url, :is_active, :limit_interval ,:limit_count, :limit_seconds, :timeout)"
                            ),
                            {"id": -1, "name": "115ç½‘ç›˜", "url": "https://115.com", "is_active": True,"limit_interval":10000000, "limit_count": 1, "limit_seconds": 10000000, "timeout": 1}
                        )
                        db.commit()
                        logger.info("å·²æ·»åŠ å±è”½ç«™ç‚¹è®°å½• (id=-1, name=115ç½‘ç›˜, is_active=True)")
                    else:
                        logger.info("å±è”½ç«™ç‚¹è®°å½•å·²å­˜åœ¨ï¼Œè·³è¿‡æ·»åŠ ")
                else:
                    # å…³é—­å±è”½ï¼šåˆ é™¤id=-1çš„ç«™ç‚¹è®°å½•
                    existing = Site.get(db, -1)
                    if existing:
                        Site.delete(db, -1)
                        logger.info("å·²åˆ é™¤å±è”½ç«™ç‚¹è®°å½• (id=-1)")
                    else:
                        logger.info("å±è”½ç«™ç‚¹è®°å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡åˆ é™¤")
                        
        except Exception as e:
            logger.error(f"æ›´æ–°å±è”½ç«™ç‚¹è®°å½•å¤±è´¥: {e}")

    def _convert_nullbr_to_pansou_format(self, nullbr_resources: List[Dict]) -> List[Dict]:
        """
        å°† Nullbr èµ„æºæ ¼å¼è½¬æ¢ä¸ºç»Ÿä¸€çš„èµ„æºæ ¼å¼
        
        Nullbr æ ¼å¼: {"title": "...", "share_link": "...", "size": "...", "resolution": "...", "season_list": [...]}
        ç»Ÿä¸€æ ¼å¼: {"url": "...", "title": "...", "update_time": ""}
        
        :param nullbr_resources: Nullbr è¿”å›çš„èµ„æºåˆ—è¡¨
        :return: ç»Ÿä¸€æ ¼å¼çš„èµ„æºåˆ—è¡¨
        """
        converted = []
        for resource in nullbr_resources:
            converted.append({
                "url": resource.get("share_link", ""),
                "title": resource.get("title", ""),
                "update_time": ""  # Nullbr æ²¡æœ‰æ›´æ–°æ—¶é—´å­—æ®µ
            })
        return converted

    def _convert_hdhive_to_pansou_format(self, hdhive_resources: List[Any]) -> List[Dict]:
        """
        å°† HDHive èµ„æºæ ¼å¼è½¬æ¢ä¸ºç»Ÿä¸€çš„èµ„æºæ ¼å¼
        
        HDHive ResourceInfo: title, share_url, share_size, website, is_free, unlock_points ç­‰
        ç»Ÿä¸€æ ¼å¼: {"url": "...", "title": "...", "update_time": ""}
        
        :param hdhive_resources: HDHive è¿”å›çš„èµ„æºåˆ—è¡¨
        :return: ç»Ÿä¸€æ ¼å¼çš„èµ„æºåˆ—è¡¨
        """
        converted = []
        for resource in hdhive_resources:
            # HDHive èµ„æºå¯èƒ½æ˜¯å¯¹è±¡æˆ–å­—å…¸
            if hasattr(resource, 'url'):
                url = resource.url or ""
            elif isinstance(resource, dict):
                url = resource.get("url", "") or resource.get("share_url", "")
            else:
                url = ""
            
            if hasattr(resource, 'title'):
                title = resource.title or ""
            elif isinstance(resource, dict):
                title = resource.get("title", "")
            else:
                title = ""
            
            if url:  # åªæ·»åŠ æœ‰ URL çš„èµ„æº
                converted.append({
                    "url": url,
                    "title": title,
                    "update_time": ""
                })
        return converted

    def _search_hdhive(
        self,
        mediainfo: MediaInfo,
        media_type: MediaType,
        season: Optional[int] = None
    ) -> List[Dict]:
        """
        ä½¿ç”¨ HDHive æœç´¢èµ„æº
        ä¼˜å…ˆä½¿ç”¨åŒæ­¥ç‰ˆæœ¬ï¼Œå¼‚å¸¸æ—¶å›é€€åˆ°å¼‚æ­¥ç‰ˆæœ¬
        
        :param mediainfo: åª’ä½“ä¿¡æ¯
        :param media_type: åª’ä½“ç±»å‹ï¼ˆMOVIE æˆ– TVï¼‰
        :param season: å­£å·ï¼ˆç”µè§†å‰§æ—¶ä½¿ç”¨ï¼‰
        :return: 115ç½‘ç›˜èµ„æºåˆ—è¡¨ï¼ˆç»Ÿä¸€æ ¼å¼ï¼‰
        """
        from .lib.hdhive import MediaType as HDHiveMediaType
        if not mediainfo.tmdb_id:
            logger.warning(f"âš ï¸ {mediainfo.title} ç¼ºå°‘ TMDB IDï¼Œæ— æ³•ä½¿ç”¨ HDHive æŸ¥è¯¢")
            return []

        hdhive_media_type = HDHiveMediaType.MOVIE if media_type == MediaType.MOVIE else HDHiveMediaType.TV
        
        
        
        # # æ–¹æ³•2: å›é€€åˆ°å¼‚æ­¥å®¢æˆ·ç«¯ï¼ˆç”¨æˆ·å/å¯†ç æ¨¡å¼ï¼‰
        # if self._hdhive_username and self._hdhive_password:
        #     try:
        #         import asyncio
        #         import os
        #         from .lib.hdhive import create_async_client as create_hdhive_async_client
                
        #         proxy_host = os.environ.get("PROXY_HOST")
        #         proxy = {"http": proxy_host, "https": proxy_host} if proxy_host else None
                
        #         logger.info(f"ä½¿ç”¨ HDHive (Async) æŸ¥è¯¢: {mediainfo.title} (TMDB ID: {mediainfo.tmdb_id})")
                
        #         async def async_search():
        #             async with create_hdhive_async_client(
        #                 username=self._hdhive_username,
        #                 password=self._hdhive_password,
        #                 headless=True,
        #                 proxy=proxy
        #             ) as client:
        #                 # è·å–åª’ä½“ä¿¡æ¯
        #                 media = await client.get_media_by_tmdb_id(mediainfo.tmdb_id, hdhive_media_type)
        #                 if not media:
        #                     return []
                        
        #                 # è·å–èµ„æºåˆ—è¡¨
        #                 resources_result = await client.get_resources(media.slug, hdhive_media_type, media_id=media.id)
        #                 if not resources_result or not resources_result.success:
        #                     return []
                        
        #                 # è¿‡æ»¤å…è´¹çš„ 115 èµ„æºå¹¶è·å–åˆ†äº«é“¾æ¥
        #                 free_115_resources = []
        #                 for res in resources_result.resources:
        #                     if hasattr(res, 'website') and res.website.value == '115' and res.is_free:
        #                         share_result = await client.get_share_url_by_click(res.slug)
        #                         if share_result and share_result.url:
        #                             free_115_resources.append({
        #                                 "url": share_result.url,
        #                                 "title": res.title,
        #                                 "update_time": ""
        #                             })
                        
        #                 return free_115_resources
                
        #         # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
        #         loop = asyncio.new_event_loop()
        #         asyncio.set_event_loop(loop)
        #         try:
        #             results = loop.run_until_complete(async_search())
        #         finally:
        #             loop.close()
                
        #         if results:
        #             logger.info(f"HDHive (Async) æ‰¾åˆ° {len(results)} ä¸ªå…è´¹ 115 èµ„æº")
        #         else:
        #             logger.info(f"HDHive (Async) æœªæ‰¾åˆ°å…è´¹ 115 èµ„æº")
        #         return results
                
        #     except Exception as e:
        #         logger.error(f"HDHive (Async) æŸ¥è¯¢å¤±è´¥: {e}")
        #         return []
        
        # æ–¹æ³•1: å°è¯•ä½¿ç”¨åŒæ­¥å®¢æˆ·ç«¯ï¼ˆCookie æ¨¡å¼ï¼‰
        if self._hdhive_client:
            try:
                logger.info(f"ä½¿ç”¨ HDHive (Sync) æŸ¥è¯¢: {mediainfo.title} (TMDB ID: {mediainfo.tmdb_id})")
                
                # è·å–åª’ä½“ä¿¡æ¯
                with self._hdhive_client as client:
                    media = client.get_media_by_tmdb_id(mediainfo.tmdb_id, hdhive_media_type)
                    if not media:
                        logger.info(f"HDHive (Sync) æœªæ‰¾åˆ°åª’ä½“: {mediainfo.title}")
                        return []
                    
                    # è·å–èµ„æºåˆ—è¡¨
                    resources_result = client.get_resources(media.slug, hdhive_media_type, media_id=media.id)
                    if not resources_result or not resources_result.success:
                        logger.info(f"HDHive (Sync) è·å–èµ„æºåˆ—è¡¨å¤±è´¥: {mediainfo.title}")
                        return []
                    
                    # è¿‡æ»¤å…è´¹çš„ 115 èµ„æº
                    free_115_resources = []
                    for res in resources_result.resources:
                        if hasattr(res, 'website') and res.website.value == '115' and res.is_free:
                            # è·å–åˆ†äº«é“¾æ¥
                            share_result = client.get_share_url(res.slug)
                            if share_result and share_result.url:
                                free_115_resources.append({
                                    "url": share_result.url,
                                    "title": res.title,
                                    "update_time": ""
                                })
                    
                    if free_115_resources:
                        logger.info(f"HDHive (Sync) æ‰¾åˆ° {len(free_115_resources)} ä¸ªå…è´¹ 115 èµ„æº")
                        return free_115_resources
                    else:
                        logger.info(f"HDHive (Sync) æœªæ‰¾åˆ°å…è´¹ 115 èµ„æº")
                        return []
                        
            except Exception as e:
                logger.warning(f"HDHive (Sync) æŸ¥è¯¢å¤±è´¥: {e}ï¼Œå°è¯•å¼‚æ­¥æ¨¡å¼...")
        return []

    def _check_and_finish_subscribe(self, subscribe, mediainfo, success_episodes):
        """
        æ£€æŸ¥è®¢é˜…æ˜¯å¦å®Œæˆï¼Œå¦‚æœå®Œæˆåˆ™è°ƒç”¨å®˜æ–¹æ¥å£
        
        :param subscribe: è®¢é˜…å¯¹è±¡
        :param mediainfo: åª’ä½“ä¿¡æ¯
        :param success_episodes: æœ¬æ¬¡æˆåŠŸè½¬å­˜çš„é›†æ•°åˆ—è¡¨ï¼ˆç”µå½±ä¸º[1]ï¼‰
        """
        try:
            # 1. æ›´æ–° note å­—æ®µï¼ˆè®°å½•å·²ä¸‹è½½é›†æ•°ï¼Œä¸ç³»ç»Ÿè®¢é˜…æ£€æŸ¥å…¼å®¹ï¼‰
            # ç³»ç»Ÿä¼šè¯»å– note å­—æ®µæ¥åˆ¤æ–­å“ªäº›é›†å·²ä¸‹è½½ï¼Œé¿å… lack_episode è¢«é‡ç½®
            current_note = subscribe.note or []
            if mediainfo.type == MediaType.TV:
                new_note = list(set(current_note).union(set(success_episodes)))
            else:
                # ç”µå½±ç”¨ [1] è¡¨ç¤ºå·²ä¸‹è½½
                new_note = list(set(current_note).union({1}))
            
            # 2. æ›´æ–°ç¼ºå¤±é›†æ•°
            current_lack = subscribe.lack_episode
            new_lack = max(0, current_lack - len(success_episodes))
            
            # 3. ä¸€æ¬¡æ€§æ›´æ–° note å’Œ lack_episode
            update_data = {}
            if new_note != current_note:
                update_data["note"] = new_note
                logger.info(f"æ›´æ–°è®¢é˜… {subscribe.name} note å­—æ®µï¼š{current_note} -> {new_note}")
            if new_lack != current_lack:
                update_data["lack_episode"] = new_lack
                logger.info(f"æ›´æ–°è®¢é˜… {subscribe.name} ç¼ºå¤±é›†æ•°ï¼š{current_lack} -> {new_lack}")
            
            if update_data:
                SubscribeOper().update(subscribe.id, update_data)
            
            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if new_lack == 0:
                logger.info(f"è®¢é˜… {subscribe.name} æ‰€æœ‰å†…å®¹å·²è½¬å­˜å®Œæˆï¼Œå‡†å¤‡å®Œæˆè®¢é˜…")
                
                # ç”Ÿæˆå…ƒæ•°æ®
                meta = MetaInfo(subscribe.name)
                meta.year = subscribe.year
                meta.begin_season = subscribe.season or None
                try:
                    meta.type = MediaType(subscribe.type)
                except ValueError:
                    logger.error(f'è®¢é˜… {subscribe.name} ç±»å‹é”™è¯¯ï¼š{subscribe.type}')
                    return
                
                # è°ƒç”¨å®˜æ–¹å®Œæˆè®¢é˜…æ¥å£
                try:
                    SubscribeChain().finish_subscribe_or_not(
                        subscribe=subscribe,
                        meta=meta,
                        mediainfo=mediainfo,
                        downloads=None,  # æˆ‘ä»¬å·²ç»æ›´æ–°äº† lack_episode
                        lefts={},        # æ²¡æœ‰å‰©ä½™é›†æ•°
                        force=True       # å¼ºåˆ¶å®Œæˆ
                    )
                    logger.info(f"âœ… è®¢é˜… {subscribe.name} å·²å®Œæˆå¹¶ç§»è‡³å†å²è®°å½•")
                    # å‘é€è®¢é˜…å®Œæˆé€šçŸ¥
                    if self._notify:
                        season_text = f" ç¬¬{subscribe.season}å­£" if subscribe.type == MediaType.TV.value and subscribe.season else ""
                        self.post_message(
                            mtype=NotificationType.Plugin,
                            title="ã€115ç½‘ç›˜è®¢é˜…è¿½æ›´ã€‘è®¢é˜…å®Œæˆ",
                            text=f"ğŸ‰ {subscribe.name}{season_text} æ‰€æœ‰å†…å®¹å·²è½¬å­˜å®Œæˆï¼Œè®¢é˜…å·²ç§»è‡³å†å²è®°å½•ã€‚"
                        )
                except Exception as e:
                    logger.error(f"å®Œæˆè®¢é˜…æ—¶å‡ºé”™ï¼š{e}", exc_info=True)
        
        except Exception as e:
            logger.error(f"æ£€æŸ¥è®¢é˜…å®ŒæˆçŠ¶æ€æ—¶å‡ºé”™ï¼š{e}", exc_info=True)

    def _pansou_search(self, keyword: str) -> List[Dict]:
        """
        PanSou æœç´¢çš„é€šç”¨é€»è¾‘
        
        :param keyword: æœç´¢å…³é”®è¯
        :return: 115ç½‘ç›˜èµ„æºåˆ—è¡¨
        """
        cloud_types = ["115"] if self._only_115 else None
        
        channels = None
        if self._pansou_channels and self._pansou_channels.strip():
            channels = [ch.strip() for ch in self._pansou_channels.split(',') if ch.strip()]
        
        search_results = self._pansou_client.search(
            keyword=keyword,
            cloud_types=cloud_types,
            channels=channels,
            limit=20
        )
        
        results = search_results.get("results", {}) if search_results and not search_results.get("error") else {}
        return results.get("115ç½‘ç›˜", [])

    def _search_resources(
        self,
        mediainfo: MediaInfo,
        media_type: MediaType,
        season: Optional[int] = None
    ) -> List[Dict]:
        """
        ç»Ÿä¸€çš„èµ„æºæœç´¢æ–¹æ³•ï¼Œæ”¯æŒç”µå½±å’Œç”µè§†å‰§
        æœç´¢ä¼˜å…ˆçº§: Nullbr > HDHive > PanSou
        
        :param mediainfo: åª’ä½“ä¿¡æ¯
        :param media_type: åª’ä½“ç±»å‹ï¼ˆMOVIE æˆ– TVï¼‰
        :param season: å­£å·ï¼ˆç”µè§†å‰§å¿…éœ€ï¼‰
        :return: 115ç½‘ç›˜èµ„æºåˆ—è¡¨
        """
        p115_results = []

        # 1. ä¼˜å…ˆä½¿ç”¨ NullBR
        if self._nullbr_priority and self._nullbr_enabled:
            # æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦å·²åˆå§‹åŒ–
            if not self._nullbr_client:
                logger.warning(f"âš ï¸ Nullbr å·²å¯ç”¨ä½†æœªåˆå§‹åŒ–ï¼ˆç¼ºå°‘ APP ID æˆ– API Keyï¼‰ï¼Œè·³è¿‡ Nullbr æŸ¥è¯¢")
            elif not mediainfo.tmdb_id:
                logger.warning(f"âš ï¸ {mediainfo.title} ç¼ºå°‘ TMDB IDï¼Œæ— æ³•ä½¿ç”¨ Nullbr æŸ¥è¯¢")
            else:
                if media_type == MediaType.MOVIE:
                    logger.info(f"ä½¿ç”¨ Nullbr æŸ¥è¯¢ç”µå½±èµ„æº: {mediainfo.title} (TMDB ID: {mediainfo.tmdb_id})")
                    nullbr_resources = self._nullbr_client.get_movie_resources(mediainfo.tmdb_id)
                else:  # MediaType.TV
                    logger.info(f"ä½¿ç”¨ Nullbr æŸ¥è¯¢ç”µè§†å‰§èµ„æº: {mediainfo.title} S{season} (TMDB ID: {mediainfo.tmdb_id})")
                    nullbr_resources = self._nullbr_client.get_tv_resources(mediainfo.tmdb_id, season)

                if nullbr_resources:
                    p115_results = self._convert_nullbr_to_pansou_format(nullbr_resources)
                    logger.info(f"Nullbr æ‰¾åˆ° {len(p115_results)} ä¸ªèµ„æº")
                else:
                    logger.info(f"Nullbr ä¼˜å…ˆæ¨¡å¼æœªæ‰¾åˆ°èµ„æºï¼Œå°†å›é€€åˆ° HDHive/PanSou æœç´¢")
        
        # 2. å¦‚æœ Nullbr æœªæ‰¾åˆ°ï¼Œä½¿ç”¨ HDHive
        if not p115_results and self._hdhive_enabled:
            hdhive_results = self._search_hdhive(mediainfo, media_type, season)
            if hdhive_results:
                p115_results = hdhive_results
                logger.info(f"HDHive æ‰¾åˆ° {len(p115_results)} ä¸ªèµ„æº")
            else:
                logger.info(f"HDHive æœªæ‰¾åˆ°èµ„æºï¼Œå°†å›é€€åˆ° PanSou æœç´¢")
        
        # 3. å¦‚æœ HDHive ä¹Ÿæœªæ‰¾åˆ°ï¼Œä½¿ç”¨ PanSou
        if not p115_results and self._pansou_enabled and self._pansou_client:
            # æ„å»ºæœç´¢å…³é”®è¯
            if media_type == MediaType.MOVIE:
                logger.info(f"ä½¿ç”¨ PanSou æœç´¢ç”µå½±èµ„æº: {mediainfo.title}")
                search_keyword = f"{mediainfo.title} {mediainfo.year}" if mediainfo.year else mediainfo.title
                # æ‰§è¡Œæœç´¢
                p115_results = self._pansou_search(search_keyword)
            else:  # MediaType.TV
                # ç”µè§†å‰§ä½¿ç”¨é™çº§æœç´¢ç­–ç•¥
                # æœç´¢å…³é”®è¯åˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
                search_keywords = [
                    f"{mediainfo.title}ç¬¬{season}å­£",  # ä¸­æ–‡å­£å·æ ¼å¼
                    mediainfo.title
                ]

                for keyword in search_keywords:
                    logger.info(f"ä½¿ç”¨ PanSou æœç´¢ç”µè§†å‰§èµ„æº: {mediainfo.title} S{season}ï¼Œå…³é”®è¯: '{keyword}'")
                    p115_results = self._pansou_search(keyword)
                    if p115_results:
                        logger.info(f"å…³é”®è¯ '{keyword}' æœç´¢åˆ° {len(p115_results)} ä¸ªç»“æœ")
                        break
                    else:
                        logger.info(f"å…³é”®è¯ '{keyword}' æ— ç»“æœï¼Œå°è¯•ä¸‹ä¸€ä¸ªé™çº§å…³é”®è¯")
        
        return p115_results

    def _send_transfer_notification(self, transfer_details: List[Dict[str, Any]], total_count: int):
        """
        å‘é€è½¬å­˜å®Œæˆé€šçŸ¥

        :param transfer_details: è½¬å­˜è¯¦æƒ…åˆ—è¡¨
        :param total_count: è½¬å­˜æ€»æ•°
        """
        if not transfer_details:
            return

        # æ„å»ºé€šçŸ¥æ–‡æœ¬
        text_lines = []
        first_image = None

        for detail in transfer_details:
            if detail.get("type") == "ç”µå½±":
                title = detail.get("title", "æœªçŸ¥")
                year = detail.get("year", "")
                text_lines.append(f"ğŸ¬ {title} ({year})")
                if not first_image and detail.get("image"):
                    first_image = detail.get("image")
            else:
                title = detail.get("title", "æœªçŸ¥")
                season = detail.get("season", 1)
                episodes = detail.get("episodes", [])
                episodes.sort()
                # æ ¼å¼åŒ–é›†æ•°æ˜¾ç¤º
                if len(episodes) <= 5:
                    ep_str = ", ".join([f"E{e:02d}" for e in episodes])
                else:
                    ep_str = f"E{episodes[0]:02d}-E{episodes[-1]:02d} å…±{len(episodes)}é›†"
                text_lines.append(f"ğŸ“º {title} S{season:02d} {ep_str}")
                if not first_image and detail.get("image"):
                    first_image = detail.get("image")

        # é™åˆ¶æ˜¾ç¤ºæ•°é‡ï¼Œé¿å…é€šçŸ¥è¿‡é•¿
        if len(text_lines) > 10:
            text_lines = text_lines[:10]
            text_lines.append(f"... ç­‰å…± {len(transfer_details)} é¡¹")

        self.post_message(
            mtype=NotificationType.Plugin,
            title=f"ã€115ç½‘ç›˜è®¢é˜…è¿½æ›´ã€‘è½¬å­˜å®Œæˆ",
            text=f"æœ¬æ¬¡å…±è½¬å­˜ {total_count} ä¸ªæ–‡ä»¶\n\n" + "\n".join(text_lines)
        )

    def stop_service(self):
        """é€€å‡ºæ’ä»¶"""
        try:
            if self._scheduler:
                self._scheduler.remove_all_jobs()
                if self._scheduler.running:
                    self._scheduler.shutdown()
                self._scheduler = None
        except Exception as e:
            logger.error(f"é€€å‡ºæ’ä»¶å¤±è´¥ï¼š{str(e)}")

    def sync_subscribes(self):
        """åŒæ­¥è®¢é˜…ï¼Œæœç´¢å¹¶è½¬å­˜ç¼ºå¤±å‰§é›†"""
        with lock:
            self._do_sync()

    def _do_sync(self):
        """æ‰§è¡ŒåŒæ­¥"""
        # æ£€æŸ¥è‡³å°‘æœ‰ä¸€ä¸ªæœç´¢å®¢æˆ·ç«¯å¯ç”¨
        if not self._pansou_enabled and not self._nullbr_enabled and not self._hdhive_enabled:
            logger.error("PanSouã€Nullbr å’Œ HDHive æœç´¢æºå‡æœªå¯ç”¨ï¼Œè¯·è‡³å°‘å¯ç”¨ä¸€ä¸ªæœç´¢æº")
            if self._notify:
                self.post_message(
                    mtype=NotificationType.Plugin,
                    title="ã€115ç½‘ç›˜è®¢é˜…è¿½æ›´ã€‘é…ç½®é”™è¯¯",
                    text="PanSouã€Nullbr å’Œ HDHive æœç´¢æºå‡æœªå¯ç”¨ï¼Œè¯·è‡³å°‘å¯ç”¨ä¸€ä¸ªæœç´¢æºã€‚"
                )
            return

        # æ£€æŸ¥å·²å¯ç”¨çš„æœç´¢æºæ˜¯å¦æˆåŠŸåˆå§‹åŒ–
        has_valid_client = False
        if self._pansou_enabled:
            if self._pansou_client:
                has_valid_client = True
            else:
                logger.warning("PanSou å·²å¯ç”¨ä½†å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ PanSou URL é…ç½®")

        if self._nullbr_enabled:
            if self._nullbr_client:
                has_valid_client = True
            else:
                logger.warning("Nullbr å·²å¯ç”¨ä½†å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ APP ID å’Œ API Key é…ç½®")

        if self._hdhive_enabled:
            # HDHive å¯ä»¥æœ‰åŒæ­¥å®¢æˆ·ç«¯æˆ–ä»…é…ç½®ç”¨æˆ·åå¯†ç ï¼ˆç”¨äºå¼‚æ­¥å›é€€ï¼‰
            if self._hdhive_client or (self._hdhive_username and self._hdhive_password):
                has_valid_client = True
            else:
                logger.warning("HDHive å·²å¯ç”¨ä½†ç¼ºå°‘å¿…è¦é…ç½®ï¼ˆCookie æˆ– ç”¨æˆ·å/å¯†ç ï¼‰")

        if not has_valid_client:
            logger.error("æ‰€æœ‰å·²å¯ç”¨çš„æœç´¢æºå‡åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
            if self._notify:
                self.post_message(
                    mtype=NotificationType.Plugin,
                    title="ã€115ç½‘ç›˜è®¢é˜…è¿½æ›´ã€‘é…ç½®é”™è¯¯",
                    text="æ‰€æœ‰å·²å¯ç”¨çš„æœç´¢æºå‡åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ PanSou URL æˆ– Nullbr APP ID/API Key é…ç½®ã€‚"
                )
            return
        
        if not self._p115_manager:
            logger.error("115 å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ Cookie é…ç½®")
            return

        # éªŒè¯ 115 ç™»å½•çŠ¶æ€
        if not self._p115_manager.check_login():
            logger.error("115 ç™»å½•å¤±è´¥ï¼ŒCookie å¯èƒ½å·²è¿‡æœŸ")
            if self._notify:
                self.post_message(
                    mtype=NotificationType.Manual,
                    title="ã€115ç½‘ç›˜è®¢é˜…è¿½æ›´ã€‘ç™»å½•å¤±è´¥",
                    text="115 Cookie å¯èƒ½å·²è¿‡æœŸï¼Œè¯·æ›´æ–°é…ç½®åé‡è¯•ã€‚"
                )
            return

        logger.info("å¼€å§‹æ‰§è¡Œ 115 ç½‘ç›˜è®¢é˜…è¿½æ›´...")
        if self._notify:
            self.post_message(
                mtype=NotificationType.Plugin,
                title="ã€115ç½‘ç›˜è®¢é˜…è¿½æ›´ã€‘å¼€å§‹æ‰§è¡Œ",
                text="æ­£åœ¨æ‰«æè®¢é˜…åˆ—è¡¨ï¼Œæœç´¢ç½‘ç›˜èµ„æºå¹¶è½¬å­˜ç¼ºå¤±å†…å®¹..."
            )

        # é‡ç½® API è°ƒç”¨è®¡æ•°å™¨
        if self._p115_manager:
            self._p115_manager.reset_api_call_count()
        if self._pansou_client:
            self._pansou_client.reset_api_call_count()
        if self._nullbr_client:
            self._nullbr_client.reset_api_call_count()

        # è·å–æ‰€æœ‰è®¢é˜…ï¼ŒçŠ¶æ€ä¸º R (è®¢é˜…ä¸­) çš„
        # ä½¿ç”¨æ–°ä¼šè¯é¿å… ScopedSession ç¼“å­˜é—®é¢˜ï¼Œç¡®ä¿è·å–æœ€æ–°æ•°æ®
        with SessionFactory() as db:
            subscribes = SubscribeOper(db=db).list("N,R")
        
        if not subscribes:
            logger.info("æ²¡æœ‰è®¢é˜…ä¸­çš„æ•°æ®")
            if self._notify:
                self.post_message(
                    mtype=NotificationType.Plugin,
                    title="ã€115ç½‘ç›˜è®¢é˜…è¿½æ›´ã€‘æ‰§è¡Œå®Œæˆ",
                    text="å½“å‰æ²¡æœ‰è®¢é˜…ä¸­çš„åª’ä½“æ•°æ®ã€‚"
                )
            return

        # åˆ†ç±»è®¢é˜…
        tv_subscribes = [s for s in subscribes if s.type == MediaType.TV.value]
        movie_subscribes = [s for s in subscribes if s.type == MediaType.MOVIE.value]

        if not tv_subscribes and not movie_subscribes:
            logger.info("æ²¡æœ‰ç”µè§†å‰§æˆ–ç”µå½±è®¢é˜…")
            return

        logger.info(f"å…±æœ‰ {len(tv_subscribes)} ä¸ªç”µè§†å‰§è®¢é˜…ã€{len(movie_subscribes)} ä¸ªç”µå½±è®¢é˜…å¾…å¤„ç†")

        downloadchain = DownloadChain()
        history: List[dict] = self.get_data('history') or []
        transferred_count = 0
        # ç”¨äºé€šçŸ¥çš„è½¬å­˜è¯¦æƒ…åˆ—è¡¨
        transfer_details: List[Dict[str, Any]] = []

        # æ’é™¤è®¢é˜…IDåˆ—è¡¨
        exclude_ids = set(self._exclude_subscribes) if self._exclude_subscribes else set()
        if exclude_ids:
            logger.info(f"æ’é™¤è®¢é˜…ID: {exclude_ids}")

        # å¤„ç†ç”µå½±è®¢é˜…
        for subscribe in movie_subscribes:
            if global_vars.is_system_stopped:
                break

            if subscribe.id in exclude_ids:
                logger.info(f"è®¢é˜… {subscribe.name} (ID:{subscribe.id}) åœ¨æ’é™¤åˆ—è¡¨ä¸­ï¼Œè·³è¿‡å¤„ç†")
                continue

            try:
                logger.info(f"å¤„ç†ç”µå½±è®¢é˜…ï¼š{subscribe.name} ({subscribe.year})")

                # æ£€æŸ¥å†å²è®°å½•æ˜¯å¦å·²æˆåŠŸè½¬å­˜
                # éä¸¥æ ¼æ¨¡å¼ä¸‹ï¼Œåªè·³è¿‡å®Œç¾åŒ¹é…çš„ï¼Œä½åˆ†çš„å¯ä»¥ç»§ç»­æ´—ç‰ˆ
                movie_history_score = -1  # -1 è¡¨ç¤ºæœªè½¬å­˜è¿‡
                movie_perfect_match = False
                for h in history:
                    if (h.get("title") == subscribe.name
                            and h.get("type") == "ç”µå½±"
                            and h.get("status") == "æˆåŠŸ"):
                        score = h.get("filter_score", 0)
                        perfect = h.get("perfect_match", False)
                        if score > movie_history_score:
                            movie_history_score = score
                            movie_perfect_match = perfect

                # best_version=1 è¡¨ç¤ºå¼€å¯æ´—ç‰ˆï¼ˆéä¸¥æ ¼æ¨¡å¼ï¼‰
                is_best_version = bool(subscribe.best_version)

                if movie_history_score >= 0:
                    if not is_best_version or movie_perfect_match:
                        logger.info(f"ç”µå½± {subscribe.name} å·²åœ¨å†å²è®°å½•ä¸­(æ´—ç‰ˆ:{is_best_version}, å®Œç¾åŒ¹é…:{movie_perfect_match})ï¼Œè·³è¿‡")
                        continue
                    else:
                        logger.info(f"ç”µå½± {subscribe.name} æ´—ç‰ˆä¸­ï¼Œå†å²åˆ†æ•° {movie_history_score}ï¼Œå°è¯•å¯»æ‰¾æ›´ä¼˜èµ„æº")

                # ç”Ÿæˆå…ƒæ•°æ®
                meta = MetaInfo(subscribe.name)
                meta.year = subscribe.year
                meta.type = MediaType.MOVIE

                # è¯†åˆ«åª’ä½“ä¿¡æ¯
                mediainfo: MediaInfo = self.chain.recognize_media(
                    meta=meta,
                    mtype=MediaType.MOVIE,
                    tmdbid=subscribe.tmdbid,
                    doubanid=subscribe.doubanid,
                    cache=True
                )
                if not mediainfo:
                    logger.warn(f"æ— æ³•è¯†åˆ«åª’ä½“ä¿¡æ¯ï¼š{subscribe.name}")
                    continue

                # æœç´¢ç½‘ç›˜èµ„æº
                p115_results = self._search_resources(
                    mediainfo=mediainfo,
                    media_type=MediaType.MOVIE
                )

                if not p115_results:
                    logger.info(f"æœªæ‰¾åˆ°ç”µå½± {mediainfo.title} çš„ 115 ç½‘ç›˜èµ„æº")
                    continue

                logger.info(f"æ‰¾åˆ° {len(p115_results)} ä¸ª 115 ç½‘ç›˜èµ„æº")

                # åˆ›å»ºè®¢é˜…è¿‡æ»¤æ¡ä»¶ï¼ˆbest_version=1 æ—¶ä¸ºéä¸¥æ ¼æ¨¡å¼/æ´—ç‰ˆæ¨¡å¼ï¼‰
                subscribe_filter = SubscribeFilter(
                    quality=subscribe.quality,
                    resolution=subscribe.resolution,
                    effect=subscribe.effect,
                    strict=not is_best_version
                )
                if subscribe_filter.has_filters():
                    mode_text = "æ´—ç‰ˆæ¨¡å¼" if is_best_version else "ä¸¥æ ¼æ¨¡å¼"
                    logger.info(f"ç”µå½± {subscribe.name} è¿‡æ»¤æ¡ä»¶({mode_text}) - è´¨é‡: {subscribe.quality}, åˆ†è¾¨ç‡: {subscribe.resolution}, ç‰¹æ•ˆ: {subscribe.effect}")

                # éå†æœç´¢ç»“æœï¼Œå°è¯•æ‰¾åˆ°å¹¶è½¬å­˜ç”µå½±
                movie_transferred = False
                for resource in p115_results:
                    if movie_transferred:
                        break

                    share_url = resource.get("url", "")
                    resource_title = resource.get("title", "")

                    if not share_url:
                        continue

                    logger.info(f"æ£€æŸ¥åˆ†äº«ï¼š{resource_title} - {share_url}")

                    try:
                        # å…ˆæ£€æŸ¥åˆ†äº«é“¾æ¥æ˜¯å¦æœ‰æ•ˆ
                        share_status = self._p115_manager.check_share_status(share_url)
                        if not share_status.is_valid:
                            logger.warning(f"åˆ†äº«é“¾æ¥æ— æ•ˆï¼š{share_url}ï¼ŒåŸå› ï¼š{share_status.status_text}")
                            continue

                        share_files = self._p115_manager.list_share_files(share_url)
                        if not share_files:
                            logger.info(f"åˆ†äº«é“¾æ¥æ— å†…å®¹ï¼š{share_url}")
                            continue

                        # åŒ¹é…ç”µå½±æ–‡ä»¶ï¼ˆæŸ¥æ‰¾æœ€å¤§çš„è§†é¢‘æ–‡ä»¶ï¼Œåº”ç”¨è¿‡æ»¤æ¡ä»¶ï¼‰
                        matched_file = FileMatcher.match_movie_file(
                            share_files, mediainfo.title,
                            subscribe_filter=subscribe_filter
                        )

                        if matched_file:
                            file_name = matched_file.get('name', '')
                            logger.info(f"æ‰¾åˆ°åŒ¹é…æ–‡ä»¶ï¼š{file_name}")

                            # è®¡ç®—å½“å‰æ–‡ä»¶çš„è¿‡æ»¤åˆ†æ•°å’Œæ˜¯å¦å®Œç¾åŒ¹é…
                            _, current_score = subscribe_filter.match(file_name) if subscribe_filter.has_filters() else (True, 0)
                            is_perfect = subscribe_filter.is_perfect_match(file_name) if subscribe_filter.has_filters() else True

                            # æ´—ç‰ˆæ¨¡å¼ä¸‹æ£€æŸ¥æ˜¯å¦éœ€è¦å‡çº§èµ„æº
                            if is_best_version and movie_history_score >= 0:
                                if current_score <= movie_history_score:
                                    logger.info(f"ç”µå½± {mediainfo.title} å·²æœ‰åˆ†æ•° {movie_history_score}ï¼Œå½“å‰ {current_score}ï¼Œè·³è¿‡")
                                    continue
                                else:
                                    logger.info(f"ç”µå½± {mediainfo.title} æ´—ç‰ˆï¼šæ—§åˆ†æ•° {movie_history_score} -> æ–°åˆ†æ•° {current_score}")

                            # æ„å»ºè½¬å­˜è·¯å¾„
                            save_dir = f"{self._movie_save_path}/{mediainfo.title} ({mediainfo.year})" if mediainfo.year else f"{self._movie_save_path}/{mediainfo.title}"
                            logger.info(f"è½¬å­˜ç›®æ ‡è·¯å¾„: {save_dir}")

                            # æ‰§è¡Œè½¬å­˜
                            success = self._p115_manager.transfer_file(
                                share_url=share_url,
                                file_id=matched_file.get("id"),
                                save_path=save_dir
                            )

                            # è®°å½•å†å²ï¼ˆåŒ…å«åˆ†æ•°ä¿¡æ¯ï¼‰
                            history_item = {
                                "title": mediainfo.title,
                                "year": mediainfo.year,
                                "type": "ç”µå½±",
                                "status": "æˆåŠŸ" if success else "å¤±è´¥",
                                "share_url": share_url,
                                "file_name": file_name,
                                "filter_score": current_score,
                                "perfect_match": is_perfect,
                                "time": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            }
                            history.append(history_item)

                            if success:
                                transferred_count += 1
                                movie_transferred = True
                                movie_history_score = current_score  # æ›´æ–°å†å²åˆ†æ•°
                                score_info = f"(åˆ†æ•°:{current_score}, å®Œç¾åŒ¹é…:{is_perfect})" if subscribe_filter.has_filters() else ""
                                logger.info(f"æˆåŠŸè½¬å­˜ç”µå½±ï¼š{mediainfo.title} {score_info}")

                                # æ”¶é›†è½¬å­˜è¯¦æƒ…ç”¨äºé€šçŸ¥
                                transfer_details.append({
                                    "type": "ç”µå½±",
                                    "title": mediainfo.title,
                                    "year": mediainfo.year,
                                    "image": mediainfo.get_poster_image(),
                                    "file_name": file_name
                                })

                                # æ·»åŠ ä¸‹è½½å†å²è®°å½•
                                try:
                                    DownloadHistoryOper().add(
                                        path=save_dir,
                                        type=mediainfo.type.value,
                                        title=mediainfo.title,
                                        year=mediainfo.year,
                                        tmdbid=mediainfo.tmdb_id,
                                        imdbid=mediainfo.imdb_id,
                                        tvdbid=mediainfo.tvdb_id,
                                        doubanid=mediainfo.douban_id,
                                        image=mediainfo.get_poster_image(),
                                        downloader="115ç½‘ç›˜",
                                        download_hash=matched_file.get("id"),
                                        torrent_name=resource_title,
                                        torrent_description=file_name,
                                        torrent_site="115ç½‘ç›˜",
                                        username="P115StrgmSub",
                                        date=datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                        note={"source": f"Subscribe|{subscribe.name}", "share_url": share_url}
                                    )
                                    logger.debug(f"å·²è®°å½•ç”µå½± {mediainfo.title} ä¸‹è½½å†å²")
                                except Exception as e:
                                    logger.warning(f"è®°å½•ä¸‹è½½å†å²å¤±è´¥ï¼š{e}")

                                # ç”µå½±è½¬å­˜æˆåŠŸåå®Œæˆè®¢é˜…
                                self._check_and_finish_subscribe(
                                    subscribe=subscribe,
                                    mediainfo=mediainfo,
                                    success_episodes=[1]  # ç”µå½±ç”¨ [1] è¡¨ç¤º
                                )
                            else:
                                logger.error(f"è½¬å­˜å¤±è´¥ï¼š{mediainfo.title}")

                    except Exception as e:
                        logger.error(f"å¤„ç†åˆ†äº«é“¾æ¥å‡ºé”™ï¼š{share_url}, é”™è¯¯ï¼š{str(e)}")
                        continue

            except Exception as e:
                logger.error(f"å¤„ç†ç”µå½±è®¢é˜… {subscribe.name} å‡ºé”™ï¼š{str(e)}")
                continue

        # å¤„ç†ç”µè§†å‰§è®¢é˜…
        for subscribe in tv_subscribes:
            # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦åœæ­¢
            if global_vars.is_system_stopped:
                break

            # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
            if subscribe.id in exclude_ids:
                logger.info(f"è®¢é˜… {subscribe.name} (ID:{subscribe.id}) åœ¨æ’é™¤åˆ—è¡¨ä¸­ï¼Œè·³è¿‡å¤„ç†")
                continue

            try:
                logger.info(f"è®¢é˜…ä¿¡æ¯ï¼š{subscribe.name}ï¼Œå¼€å§‹é›†æ•°ï¼š{subscribe.start_episode}, æ€»é›†æ•°ï¼š{subscribe.total_episode}, ç¼ºå¤±é›†æ•°ï¼š{subscribe.lack_episode}")
                logger.info(f"å¤„ç†è®¢é˜…ï¼š{subscribe.name} (S{subscribe.season or 1})")
                
                # æ—©æœŸæ£€æŸ¥ï¼šå¦‚æœè®¢é˜…æ˜¾ç¤ºæ²¡æœ‰ç¼ºå¤±é›†æ•°ï¼Œä¸”åª’ä½“åº“å·²å®Œæ•´ï¼Œè·³è¿‡å¤„ç†
                if subscribe.lack_episode == 0:
                    logger.info(f"{subscribe.name} S{subscribe.season or 1} è®¢é˜…æ˜¾ç¤ºåª’ä½“åº“å·²å®Œæ•´(lack_episode=0)ï¼Œè·³è¿‡")
                    continue

                # ç”Ÿæˆå…ƒæ•°æ®
                meta = MetaInfo(subscribe.name)
                meta.year = subscribe.year
                meta.begin_season = subscribe.season or 1
                meta.type = MediaType.TV

                # è¯†åˆ«åª’ä½“ä¿¡æ¯
                mediainfo: MediaInfo = self.chain.recognize_media(
                    meta=meta,
                    mtype=MediaType.TV,
                    tmdbid=subscribe.tmdbid,
                    doubanid=subscribe.doubanid,
                    cache=True
                )

                if not mediainfo:
                    logger.warn(f"æ— æ³•è¯†åˆ«åª’ä½“ä¿¡æ¯ï¼š{subscribe.name}")
                    continue

                # æ„é€ æ€»é›†æ•°ä¿¡æ¯ï¼Œç”¨äº get_no_exists_info
                totals = {}
                if subscribe.season and subscribe.total_episode:
                    totals = {subscribe.season: subscribe.total_episode}

                # è·å–ç¼ºå¤±å‰§é›†
                exist_flag, no_exists = downloadchain.get_no_exists_info(
                    meta=meta,
                    mediainfo=mediainfo,
                    totals=totals
                )
                
                if exist_flag:
                    logger.info(f"{mediainfo.title_year} S{meta.begin_season} åª’ä½“åº“ä¸­å·²å®Œæ•´å­˜åœ¨")
                    # å¦‚æœç¼ºå¤±é›†æ•°ä¸ä¸º0ï¼Œä¿®æ­£ä¸º0
                    if subscribe.lack_episode != 0:
                            SubscribeOper().update(subscribe.id, {"lack_episode": 0})
                    continue

                # è·å–ç¼ºå¤±çš„é›†æ•°åˆ—è¡¨
                season = meta.begin_season or 1
                missing_episodes = []
                # å…¼å®¹ TMDB å’Œ è±†ç“£ ID
                mediakey = mediainfo.tmdb_id or mediainfo.douban_id
                
                if no_exists and mediakey:
                    season_info = no_exists.get(mediakey, {})
                    not_exist_info = season_info.get(season)
                    if not_exist_info:
                        # NotExistMediaInfo å¯¹è±¡ï¼Œéœ€è¦è·å–å…¶ episodes å±æ€§
                        missing_episodes = not_exist_info.episodes or []
                        # å¦‚æœ episodes ä¸ºç©ºä½†æœ‰ total_episodeï¼Œè¯´æ˜ç¼ºå¤±æ•´å­£ï¼Œéœ€è¦ç”Ÿæˆé›†æ•°åˆ—è¡¨
                        if not missing_episodes and not_exist_info.total_episode:
                            start_ep = not_exist_info.start_episode or 1
                            missing_episodes = list(range(start_ep, not_exist_info.total_episode + 1))

                if not missing_episodes:
                    logger.info(f"{mediainfo.title_year} S{season} æ²¡æœ‰ç¼ºå¤±å‰§é›†ä¿¡æ¯")
                    continue
                
                # è¿‡æ»¤æ‰å°äºå¼€å§‹é›†æ•°çš„å‰§é›†
                if subscribe.start_episode:
                    original_count = len(missing_episodes)
                    missing_episodes = [ep for ep in missing_episodes if ep >= subscribe.start_episode]
                    if len(missing_episodes) < original_count:
                                                                        logger.info(f"æ ¹æ®è®¢é˜…è®¾ç½®ï¼Œè¿‡æ»¤æ‰å°äº {subscribe.start_episode} çš„å‰§é›†")

                # best_version=1 è¡¨ç¤ºå¼€å¯æ´—ç‰ˆï¼ˆéä¸¥æ ¼æ¨¡å¼ï¼‰
                is_best_version = bool(subscribe.best_version)

                # ä»å†å²è®°å½•ä¸­æ’é™¤å·²æˆåŠŸè½¬å­˜çš„é›†æ•°ï¼Œé¿å…é‡å¤è½¬å­˜
                # æ´—ç‰ˆæ¨¡å¼ä¸‹ï¼Œåªæ’é™¤å®Œç¾åŒ¹é…çš„é›†æ•°ï¼Œä½åˆ†é›†æ•°å¯ä»¥ç»§ç»­æœç´¢æ›´ä¼˜èµ„æº
                transferred_episodes = set()
                # è®°å½•æ¯é›†çš„å†å²è½¬å­˜åˆ†æ•°ï¼Œç”¨äºæ´—ç‰ˆæ¨¡å¼ä¸‹åˆ¤æ–­æ˜¯å¦éœ€è¦å‡çº§
                episode_history_scores: Dict[int, int] = {}
                for h in history:
                    if (h.get("title") == mediainfo.title
                            and h.get("season") == season
                            and h.get("status") == "æˆåŠŸ"):
                        ep = h.get("episode")
                        score = h.get("filter_score", 0)
                        perfect = h.get("perfect_match", False)

                        if not is_best_version:
                            # éæ´—ç‰ˆæ¨¡å¼ï¼ˆä¸¥æ ¼æ¨¡å¼ï¼‰ï¼šæ‰€æœ‰æˆåŠŸçš„éƒ½è·³è¿‡
                            transferred_episodes.add(ep)
                        else:
                            # æ´—ç‰ˆæ¨¡å¼ï¼šåªè·³è¿‡å®Œç¾åŒ¹é…çš„ï¼Œä½åˆ†çš„å¯ä»¥ç»§ç»­æ´—ç‰ˆ
                            if perfect:
                                transferred_episodes.add(ep)
                            else:
                                # è®°å½•å½“å‰æœ€é«˜åˆ†æ•°
                                if ep not in episode_history_scores or score > episode_history_scores[ep]:
                                    episode_history_scores[ep] = score
                
                # æ„å»ºè½¬å­˜è·¯å¾„ï¼ˆæå‰æ„å»ºä»¥ä¾¿æ£€æŸ¥ç½‘ç›˜ç›®å½•ï¼‰
                save_dir = f"{self._save_path}/{mediainfo.title}/Season {season}"
                
                # æ£€æŸ¥ç½‘ç›˜ç›®å½•ä¸­å·²å­˜åœ¨çš„å‰§é›†
                existing_episodes_in_cloud = FileMatcher.check_existing_episodes(
                    self._p115_manager, mediainfo, season, save_dir
                )
                
                # åˆå¹¶å†å²è®°å½•å’Œç½‘ç›˜å·²å­˜åœ¨çš„é›†æ•°
                all_existing = transferred_episodes | existing_episodes_in_cloud

                # æ´—ç‰ˆæ¨¡å¼ä¸‹ï¼Œéœ€è¦å‡çº§çš„é›†æ•°ï¼ˆæœ‰å†å²è®°å½•ä½†éå®Œç¾åŒ¹é…ï¼‰ä¸åº”è¯¥è¢«æ’é™¤
                # è¿™äº›é›†æ•°éœ€è¦ç»§ç»­æœç´¢æ›´å¥½çš„èµ„æº
                if is_best_version and episode_history_scores:
                    episodes_to_upgrade = set(episode_history_scores.keys())
                    all_existing = all_existing - episodes_to_upgrade
                    if episodes_to_upgrade:
                        logger.info(f"{mediainfo.title_year} S{season} æ´—ç‰ˆæ¨¡å¼ï¼š{len(episodes_to_upgrade)} é›†å¾…å‡çº§")

                if all_existing:
                    missing_episodes = [ep for ep in missing_episodes if ep not in all_existing]
                    logger.info(
                        f"{mediainfo.title_year} S{season} è·³è¿‡å·²å­˜åœ¨çš„ {len(all_existing)} é›† "
                        f"(å†å²è®°å½•:{len(transferred_episodes)}, ç½‘ç›˜:{len(existing_episodes_in_cloud)})"
                    )

                if not missing_episodes:
                    logger.info(f"{mediainfo.title_year} S{season} æ‰€æœ‰ç¼ºå¤±å‰§é›†å·²è½¬å­˜")
                    # æ›´æ–°è®¢é˜…ç¼ºå¤±é›†æ•°ä¸º 0ï¼ˆå› ä¸ºè™½ç„¶åª’ä½“åº“æ²¡æœ‰ï¼Œä½†ç½‘ç›˜å·²ç»è½¬å­˜äº†ï¼‰
                    # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½ç›´æ¥è®¾ä¸º0ï¼Œå¦åˆ™ä¸»æµç¨‹å¯èƒ½ä¼šè®¤ä¸ºå·²å®Œæˆã€‚
                    # ä½†ä¸ºäº†ä¸é‡å¤æœç´¢ï¼Œæš‚æ—¶ä¸å¤„ç† lack_episodeï¼Œåªä¾èµ– history è¿‡æ»¤
                    continue

                logger.info(f"{mediainfo.title_year} S{season} å¾…è½¬å­˜å‰§é›†ï¼š{missing_episodes}")

                # æœç´¢ç½‘ç›˜èµ„æº
                p115_results = self._search_resources(
                    mediainfo=mediainfo,
                    media_type=MediaType.TV,
                    season=season
                )

                if not p115_results:
                    logger.info(f"æœªæ‰¾åˆ° {mediainfo.title} S{season} çš„ 115 ç½‘ç›˜èµ„æº")
                    continue

                logger.info(f"æ‰¾åˆ° {len(p115_results)} ä¸ª 115 ç½‘ç›˜èµ„æº")

                # åˆ›å»ºè®¢é˜…è¿‡æ»¤æ¡ä»¶
                subscribe_filter = SubscribeFilter(
                    quality=subscribe.quality,
                    resolution=subscribe.resolution,
                    effect=subscribe.effect,
                    strict=not is_best_version
                )
                if subscribe_filter.has_filters():
                    mode_text = "æ´—ç‰ˆæ¨¡å¼" if is_best_version else "ä¸¥æ ¼æ¨¡å¼"
                    logger.info(f"{mediainfo.title} S{season} è¿‡æ»¤æ¡ä»¶({mode_text}) - è´¨é‡: {subscribe.quality}, åˆ†è¾¨ç‡: {subscribe.resolution}, ç‰¹æ•ˆ: {subscribe.effect}")

                # æˆåŠŸè½¬å­˜çš„é›†æ•°åˆ—è¡¨
                success_episodes = []

                # æ„å»ºè½¬å­˜è·¯å¾„ï¼ˆæå‰æ„å»ºï¼Œæ‰¹é‡è½¬å­˜å…±ç”¨ï¼‰
                save_dir = f"{self._save_path}/{mediainfo.title}/Season {season}"

                # éå†æœç´¢ç»“æœï¼Œå°è¯•æ‰¾åˆ°å¹¶è½¬å­˜ç¼ºå¤±å‰§é›†
                for resource in p115_results:
                    # æ£€æŸ¥å•æ¬¡åŒæ­¥ä¸Šé™
                    if transferred_count >= self._max_transfer_per_sync:
                        logger.info(f"å·²è¾¾å•æ¬¡åŒæ­¥ä¸Šé™ {self._max_transfer_per_sync}ï¼Œå‰©ä½™ {len(missing_episodes)} é›†å°†åœ¨ä¸‹æ¬¡åŒæ­¥å¤„ç†")
                        break

                    share_url = resource.get("url", "")
                    resource_title = resource.get("title", "")

                    if not share_url:
                        continue

                    # ç®€å•çš„æ ‡é¢˜è¿‡æ»¤
                    if mediainfo.title not in resource_title:
                        pass

                    logger.info(f"æ£€æŸ¥åˆ†äº«ï¼š{resource_title} - {share_url}")

                    try:
                        # å…ˆæ£€æŸ¥åˆ†äº«é“¾æ¥æ˜¯å¦æœ‰æ•ˆ
                        share_status = self._p115_manager.check_share_status(share_url)
                        if not share_status.is_valid:
                            logger.warning(f"åˆ†äº«é“¾æ¥æ— æ•ˆï¼š{share_url}ï¼ŒåŸå› ï¼š{share_status.status_text}")
                            continue

                        # åˆ—å‡ºåˆ†äº«å†…å®¹
                        share_files = self._p115_manager.list_share_files(share_url,target_season=(season if self._skip_other_season_dirs else None))
                        if not share_files:
                            logger.info(f"åˆ†äº«é“¾æ¥æ— å†…å®¹ï¼š{share_url}")
                            continue

                        logger.info(f"åˆ†äº«åŒ…å« {len(share_files)} ä¸ªæ–‡ä»¶/ç›®å½•")

                        # ç¬¬ä¸€é˜¶æ®µï¼šæ”¶é›†è¯¥åˆ†äº«ä¸­æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶ï¼ˆä¸ç«‹å³è½¬å­˜ï¼‰
                        matched_items = []  # å­˜å‚¨åŒ¹é…ä¿¡æ¯: {file, episode, score, is_perfect, is_upgrade}

                        for episode in missing_episodes[:]:
                            matched_file = FileMatcher.match_episode_file(
                                share_files,
                                mediainfo.title,
                                season,
                                episode,
                                subscribe_filter=subscribe_filter
                            )

                            if matched_file:
                                file_name = matched_file.get('name', '')
                                logger.info(f"æ‰¾åˆ°åŒ¹é…æ–‡ä»¶ï¼š{file_name} -> E{episode:02d}")

                                # è®¡ç®—å½“å‰æ–‡ä»¶çš„è¿‡æ»¤åˆ†æ•°å’Œæ˜¯å¦å®Œç¾åŒ¹é…
                                _, current_score = subscribe_filter.match(file_name) if subscribe_filter.has_filters() else (True, 0)
                                is_perfect = subscribe_filter.is_perfect_match(file_name) if subscribe_filter.has_filters() else True

                                # æ´—ç‰ˆæ¨¡å¼ä¸‹æ£€æŸ¥æ˜¯å¦éœ€è¦å‡çº§èµ„æº
                                is_upgrade = False
                                if is_best_version and episode in episode_history_scores:
                                    old_score = episode_history_scores[episode]
                                    if current_score <= old_score:
                                        logger.info(f"E{episode:02d} å·²æœ‰åˆ†æ•° {old_score}ï¼Œå½“å‰ {current_score}ï¼Œè·³è¿‡")
                                        continue
                                    else:
                                        logger.info(f"E{episode:02d} æ´—ç‰ˆï¼šæ—§åˆ†æ•° {old_score} -> æ–°åˆ†æ•° {current_score}")
                                        is_upgrade = True

                                matched_items.append({
                                    "file": matched_file,
                                    "episode": episode,
                                    "score": current_score,
                                    "is_perfect": is_perfect,
                                    "is_upgrade": is_upgrade
                                })

                        # å¦‚æœè¯¥åˆ†äº«æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å‰§é›†ï¼Œè·³è¿‡
                        if not matched_items:
                            logger.info(f"è¯¥åˆ†äº«æœªåŒ¹é…åˆ° S{season} çš„ä»»ä½•ç¼ºå¤±å‰§é›†ï¼Œå¯èƒ½æ˜¯å­£æ•°ä¸åŒ¹é…æˆ–æ–‡ä»¶åæ— æ³•è¯†åˆ«")
                            continue

                        # æ£€æŸ¥è½¬å­˜é…é¢é™åˆ¶
                        remaining_quota = self._max_transfer_per_sync - transferred_count
                        if len(matched_items) > remaining_quota:
                            logger.info(f"åŒ¹é… {len(matched_items)} é›†ï¼Œä½†å—é…é¢é™åˆ¶ä»…è½¬å­˜ {remaining_quota} é›†")
                            matched_items = matched_items[:remaining_quota]

                        # ç¬¬äºŒé˜¶æ®µï¼šæ‰¹é‡è½¬å­˜
                        file_ids = [item["file"]["id"] for item in matched_items]
                        logger.info(f"å‡†å¤‡æ‰¹é‡è½¬å­˜ {len(file_ids)} ä¸ªæ–‡ä»¶åˆ°: {save_dir}")

                        success_ids, failed_ids = self._p115_manager.transfer_files_batch(
                            share_url=share_url,
                            file_ids=file_ids,
                            save_path=save_dir,
                            batch_size=self._batch_size
                        )

                        # å°†æˆåŠŸçš„ file_id è½¬ä¸ºé›†åˆï¼Œä¾¿äºå¿«é€ŸæŸ¥æ‰¾
                        success_id_set = set(success_ids)
                        # æ”¶é›†æœ¬æ¬¡æ‰¹é‡è½¬å­˜æˆåŠŸçš„å‰§é›†å·ï¼ˆç”¨äºä¸‹è½½å†å²è®°å½•ï¼‰
                        batch_success_episodes = []

                        # ç¬¬ä¸‰é˜¶æ®µï¼šæ ¹æ®æ‰¹é‡è½¬å­˜ç»“æœå¤„ç†å†å²è®°å½•å’ŒçŠ¶æ€
                        for item in matched_items:
                            file_id = item["file"]["id"]
                            episode = item["episode"]
                            file_name = item["file"]["name"]
                            current_score = item["score"]
                            is_perfect = item["is_perfect"]
                            is_upgrade = item["is_upgrade"]
                            success = file_id in success_id_set

                            # è®°å½•å†å²
                            history_item = {
                                "title": mediainfo.title,
                                "season": season,
                                "episode": episode,
                                "status": "æˆåŠŸ" if success else "å¤±è´¥",
                                "share_url": share_url,
                                "file_name": file_name,
                                "filter_score": current_score,
                                "perfect_match": is_perfect,
                                "time": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            }
                            history.append(history_item)

                            if success:
                                transferred_count += 1

                                # æ›´æ–°å†å²åˆ†æ•°è®°å½•
                                episode_history_scores[episode] = current_score
                                # ä»ç¼ºå¤±åˆ—è¡¨ç§»é™¤
                                if episode in missing_episodes:
                                    missing_episodes.remove(episode)

                                # åªæœ‰æ–°è½¬å­˜ï¼ˆéæ´—ç‰ˆå‡çº§ï¼‰çš„æ‰åŠ å…¥ success_episodes
                                if not is_upgrade:
                                    success_episodes.append(episode)

                                score_info = f"(åˆ†æ•°:{current_score}, å®Œç¾åŒ¹é…:{is_perfect})" if subscribe_filter.has_filters() else ""
                                upgrade_info = " [æ´—ç‰ˆå‡çº§]" if is_upgrade else ""
                                logger.info(f"æˆåŠŸè½¬å­˜ï¼š{mediainfo.title} S{season:02d}E{episode:02d} {score_info}{upgrade_info}")

                                # æ”¶é›†è½¬å­˜è¯¦æƒ…ç”¨äºé€šçŸ¥ï¼ˆæŒ‰åª’ä½“èšåˆï¼‰
                                existing_detail = next(
                                    (d for d in transfer_details
                                     if d.get("title") == mediainfo.title and d.get("season") == season),
                                    None
                                )
                                if existing_detail:
                                    existing_detail["episodes"].append(episode)
                                else:
                                    transfer_details.append({
                                        "type": "ç”µè§†å‰§",
                                        "title": mediainfo.title,
                                        "year": mediainfo.year,
                                        "season": season,
                                        "episodes": [episode],
                                        "image": mediainfo.get_poster_image()
                                    })

                                # æ”¶é›†æˆåŠŸçš„å‰§é›†å·
                                batch_success_episodes.append(episode)
                            else:
                                logger.error(f"è½¬å­˜å¤±è´¥ï¼š{mediainfo.title} S{season:02d}E{episode:02d}")

                        # æ‰¹é‡è½¬å­˜å®Œæˆåï¼Œæ±‡æ€»è®°å½•ä¸‹è½½å†å²
                        if batch_success_episodes:
                            try:
                                # ä½¿ç”¨ StringUtils.format_ep æ ¼å¼åŒ–å‰§é›†åˆ—è¡¨ï¼Œå¦‚ [15, 16] -> "E15-E16"
                                episodes_str = StringUtils.format_ep(batch_success_episodes)
                                DownloadHistoryOper().add(
                                    path=save_dir,
                                    type=mediainfo.type.value,
                                    title=mediainfo.title,
                                    year=mediainfo.year,
                                    tmdbid=mediainfo.tmdb_id,
                                    imdbid=mediainfo.imdb_id,
                                    tvdbid=mediainfo.tvdb_id,
                                    doubanid=mediainfo.douban_id,
                                    seasons=f"S{season:02d}",
                                    episodes=episodes_str,
                                    image=mediainfo.get_poster_image(),
                                    downloader="115ç½‘ç›˜",
                                    download_hash=share_url,  # ä½¿ç”¨åˆ†äº«é“¾æ¥ä½œä¸ºå”¯ä¸€æ ‡è¯†
                                    torrent_name=resource_title,
                                    torrent_site="115ç½‘ç›˜",
                                    username="P115StrgmSub",
                                    date=datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                    note={"source": f"Subscribe|{subscribe.name}", "share_url": share_url}
                                )
                                logger.debug(f"å·²è®°å½• {mediainfo.title} S{season:02d} {episodes_str} ä¸‹è½½å†å²")
                            except Exception as e:
                                logger.warning(f"è®°å½•ä¸‹è½½å†å²å¤±è´¥ï¼š{e}")

                        # å¦‚æœæ‰€æœ‰ç¼ºå¤±å‰§é›†éƒ½å·²è½¬å­˜ï¼Œè·³å‡ºå¾ªç¯
                        if not missing_episodes:
                            break

                    except Exception as e:
                        logger.error(f"å¤„ç†åˆ†äº«é“¾æ¥å‡ºé”™ï¼š{share_url}, é”™è¯¯ï¼š{str(e)}")
                        continue

                # æ›´æ–°è®¢é˜…çš„ç¼ºå¤±é›†æ•°å¹¶æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if success_episodes:
                    self._check_and_finish_subscribe(
                        subscribe=subscribe,
                        mediainfo=mediainfo,
                        success_episodes=success_episodes
                    )

            except Exception as e:
                logger.error(f"å¤„ç†è®¢é˜… {subscribe.name} å‡ºé”™ï¼š{str(e)}")
                continue

        # ä¿å­˜å†å²è®°å½•
        self.save_data('history', history[-500:])  # åªä¿ç•™æœ€è¿‘500æ¡

        logger.info(f"115 ç½‘ç›˜è®¢é˜…è¿½æ›´å®Œæˆï¼Œå…±è½¬å­˜ {transferred_count} ä¸ªæ–‡ä»¶")

        # æ‰“å° API è°ƒç”¨ç»Ÿè®¡
        api_stats = []
        if self._p115_manager:
            api_stats.append(f"115æ¥å£: {self._p115_manager.get_api_call_count()}æ¬¡")
        if self._pansou_client:
            api_stats.append(f"PanSouæ¥å£: {self._pansou_client.get_api_call_count()}æ¬¡")
        if self._nullbr_client:
            api_stats.append(f"Nullbræ¥å£: {self._nullbr_client.get_api_call_count()}æ¬¡")
        if api_stats:
            logger.info(f"æœ¬æ¬¡åŒæ­¥ API è°ƒç”¨ç»Ÿè®¡: {', '.join(api_stats)}")

        # å‘é€æ±‡æ€»é€šçŸ¥
        if self._notify:
            if transferred_count > 0:
                self._send_transfer_notification(transfer_details, transferred_count)
            else:
                # æ— è½¬å­˜æ—¶ä¹Ÿå‘é€é€šçŸ¥
                self.post_message(
                    mtype=NotificationType.Plugin,
                    title="ã€115ç½‘ç›˜è®¢é˜…è¿½æ›´ã€‘æ‰§è¡Œå®Œæˆ",
                    text=f"æœ¬æ¬¡åŒæ­¥å®Œæˆï¼Œå…±å¤„ç† {len(tv_subscribes)} ä¸ªç”µè§†å‰§è®¢é˜…ã€{len(movie_subscribes)} ä¸ªç”µå½±è®¢é˜…ï¼Œæœªå‘ç°éœ€è¦è½¬å­˜çš„æ–°èµ„æºã€‚"
                )

    def api_search(self, keyword: str, apikey: str) -> dict:
        """API: æœç´¢ç½‘ç›˜èµ„æº"""
        if apikey != settings.API_TOKEN:
            return {"error": "APIå¯†é’¥é”™è¯¯"}

        if not self._pansou_client:
            return {"error": "PanSou å®¢æˆ·ç«¯æœªåˆå§‹åŒ–"}

        cloud_types = ["115"] if self._only_115 else None
        return self._pansou_client.search(keyword=keyword, cloud_types=cloud_types, limit=10)

    def api_transfer(self, share_url: str, save_path: str, apikey: str) -> dict:
        """API: è½¬å­˜åˆ†äº«é“¾æ¥"""
        if apikey != settings.API_TOKEN:
            return {"success": False, "error": "APIå¯†é’¥é”™è¯¯"}

        if not self._p115_manager:
            return {"success": False, "error": "115 å®¢æˆ·ç«¯æœªåˆå§‹åŒ–"}

        success = self._p115_manager.transfer_share(share_url, save_path or self._save_path)
        return {"success": success}

    def api_clear_history(self, apikey: str) -> dict:
        """API: æ¸…ç©ºå†å²è®°å½•"""
        if apikey != settings.API_TOKEN:
            return {"success": False, "message": "APIå¯†é’¥é”™è¯¯"}

        self.save_data('history', [])
        logger.info("115ç½‘ç›˜è®¢é˜…è¿½æ›´å†å²è®°å½•å·²æ¸…ç©º")
        return {"success": True, "message": "å†å²è®°å½•å·²æ¸…ç©º"}

    def api_list_directories(self, path: str = "/", apikey: str = "") -> dict:
        """API: åˆ—å‡º115ç½‘ç›˜æŒ‡å®šè·¯å¾„ä¸‹çš„ç›®å½•"""
        if apikey != settings.API_TOKEN:
            return {"success": False, "error": "APIå¯†é’¥é”™è¯¯"}
        
        if not self._p115_manager:
            return {"success": False, "error": "115å®¢æˆ·ç«¯æœªåˆå§‹åŒ–"}
        
        try:
            # åˆ—å‡ºç›®å½•
            directories = self._p115_manager.list_directories(path)
            
            # æ„å»ºé¢åŒ…å±‘å¯¼èˆª
            breadcrumbs = []
            if path and path != "/":
                parts = [p for p in path.split("/") if p]
                current_path = ""
                breadcrumbs.append({"name": "æ ¹ç›®å½•", "path": "/"})
                for part in parts:
                    current_path = f"{current_path}/{part}"
                    breadcrumbs.append({"name": part, "path": current_path})
            else:
                breadcrumbs.append({"name": "æ ¹ç›®å½•", "path": "/"})
            
            return {
                "success": True,
                "path": path,
                "breadcrumbs": breadcrumbs,
                "directories": directories
            }
        except Exception as e:
            logger.error(f"åˆ—å‡º115ç›®å½•å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

   

    @eventmanager.register(EventType.PluginAction)
    def remote_sync(self, event: Event):
        """è¿œç¨‹å‘½ä»¤è§¦å‘åŒæ­¥"""
        if not event:
            return
        event_data = event.event_data
        if not event_data or event_data.get("action") != "p115_sync":
            return

        logger.info("æ”¶åˆ°å‘½ä»¤ï¼Œå¼€å§‹æ‰§è¡Œ 115 ç½‘ç›˜è®¢é˜…è¿½æ›´...")
        self.post_message(
            mtype=NotificationType.Plugin,
            channel=event_data.get("channel"),
            title="ã€115ç½‘ç›˜è®¢é˜…è¿½æ›´ã€‘å¼€å§‹æ‰§è¡Œ",
            text="å·²æ”¶åˆ°è¿œç¨‹å‘½ä»¤ï¼Œæ­£åœ¨æ‰§è¡Œè®¢é˜…è¿½æ›´ä»»åŠ¡...",
            userid=event_data.get("user")
        )

        self.sync_subscribes()

        self.post_message(
            mtype=NotificationType.Plugin,
            channel=event_data.get("channel"),
            title="ã€115ç½‘ç›˜è®¢é˜…è¿½æ›´ã€‘æ‰§è¡Œå®Œæˆ",
            text="è¿œç¨‹è§¦å‘çš„è®¢é˜…è¿½æ›´ä»»åŠ¡å·²å®Œæˆï¼Œè¯¦æƒ…è¯·æŸ¥çœ‹è¿½æ›´é€šçŸ¥æˆ–å†å²è®°å½•ã€‚",
            userid=event_data.get("user")
        )
